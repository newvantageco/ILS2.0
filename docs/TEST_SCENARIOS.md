# End-to-End Test Scenarios

## Test Environment
- **URL**: http://localhost:3000
- **Database**: PostgreSQL (ils_db)
- **Server**: Node.js Express on port 3000

## ðŸ§ª Test Scenario 1: AI Assistant - First Use

### Objective
Test AI Assistant with no prior knowledge (0% autonomy)

### Steps
1. Log in as ECP/Dispenser user
2. Navigate to "AI Assistant" page
3. Verify learning progress shows 0% or low percentage
4. Ask a general business question: "What products do I sell?"
5. Observe AI response uses external AI
6. Check response metadata shows `usedExternalAi: true`
7. Provide positive feedback (thumbs up)
8. Verify learning progress increased slightly

### Expected Results
- âœ… Learning progress card displays at top
- âœ… AI responds with answer
- âœ… Source badges show "external" type
- âœ… Confidence score displayed
- âœ… Feedback buttons appear
- âœ… Progress increases after feedback

## ðŸ§ª Test Scenario 2: Knowledge Base Upload

### Objective
Upload documents and verify knowledge extraction

### Steps
1. On AI Assistant page, scroll to "Upload Knowledge" section
2. Click file input and select a PDF/DOCX document
3. Click "Upload Document" button
4. Wait for processing confirmation
5. Check "Knowledge Base" section
6. Verify document appears in list
7. Note document category
8. Check learning progress increased

### Expected Results
- âœ… Upload succeeds with success alert
- âœ… Document appears in knowledge base list
- âœ… Filename and date displayed
- âœ… Category badge shown
- âœ… Learning stats updated (document count +1)

## ðŸ§ª Test Scenario 3: Progressive Learning

### Objective
Test AI learning from repeated questions

### Steps
1. Ask the same question twice: "What is my inventory?"
2. First answer should use external AI
3. Provide positive feedback
4. Wait a moment for learning to process
5. Ask the same question again
6. Second answer should show higher confidence
7. Eventually, AI should answer without external AI

### Expected Results
- âœ… First response: external AI used
- âœ… Learning data stored
- âœ… Second response: confidence higher
- âœ… After 3-5 interactions: local answer
- âœ… Autonomy rate increases
- âœ… Source badges show "learned" type

## ðŸ§ª Test Scenario 4: Company Profile Management

### Objective
Edit company profile and verify changes persist

### Steps
1. Navigate to "Company" page
2. Click "Edit" button
3. Update company name
4. Change contact email
5. Update address
6. Change company status
7. Click "Save" button
8. Refresh page
9. Verify changes persist

### Expected Results
- âœ… Edit mode enables all fields
- âœ… Changes save successfully
- âœ… Success alert appears
- âœ… Form returns to view mode
- âœ… Data persists after refresh

## ðŸ§ª Test Scenario 5: Supplier Relationship (Dispenser)

### Objective
Create and manage supplier relationship as dispenser

### Steps
1. Log in as Dispenser user
2. Navigate to "Company" page
3. Click "Add Supplier" button
4. Select a supplier from dropdown
5. Click "Send Request"
6. Verify request appears in list
7. Check status shows "PENDING"
8. Wait for supplier approval

### Expected Results
- âœ… Dialog opens with supplier list
- âœ… Request creates successfully
- âœ… Relationship appears in "Supplier Relationships"
- âœ… Status badge shows "PENDING"
- âœ… Supplier company name displayed

## ðŸ§ª Test Scenario 6: Supplier Approval (Supplier)

### Objective
Approve dispenser relationship request as supplier

### Steps
1. Log in as Supplier user
2. Navigate to "Company" page
3. View "Dispenser Relationships" section
4. Find pending request
5. Click green checkmark (Approve)
6. Verify status changes to "APPROVED"
7. Switch to dispenser account
8. Verify their view shows "APPROVED" status

### Expected Results
- âœ… Pending requests visible
- âœ… Approve/Reject buttons appear
- âœ… Approval updates status immediately
- âœ… Badge changes to green "APPROVED"
- âœ… Both parties see updated status

## ðŸ§ª Test Scenario 7: Data Isolation Test

### Objective
Verify company data isolation (multi-tenancy)

### Steps
1. Create orders as Company A user
2. Note order IDs
3. Log out and log in as Company B user
4. Navigate to orders/dashboard
5. Verify Company A orders NOT visible
6. Create orders as Company B
7. Switch back to Company A
8. Verify Company B orders NOT visible

### Expected Results
- âœ… Each company sees only their data
- âœ… No cross-company data leakage
- âœ… AI Assistant knowledge isolated per company
- âœ… Company relationships properly filtered

## ðŸ§ª Test Scenario 8: Business Intelligence Dashboard

### Objective
View and verify BI insights and KPIs

### Steps
1. Create some test orders (5-10)
2. Add products to inventory
3. Complete some sales transactions
4. Navigate to "BI Dashboard" page
5. View KPI cards at top
6. Check trend indicators
7. Review AI insights section
8. Explore growth opportunities
9. Check for any alerts

### Expected Results
- âœ… KPI cards show metrics (Orders, Revenue, etc.)
- âœ… Trend arrows indicate up/down
- âœ… Percentage changes displayed
- âœ… AI insights generated
- âœ… Impact levels shown (High/Medium/Low)
- âœ… Opportunities list actionable items
- âœ… Alerts display if thresholds met

## ðŸ§ª Test Scenario 9: Multi-Conversation Management

### Objective
Create and manage multiple AI conversations

### Steps
1. On AI Assistant page, start new conversation
2. Ask question: "Show me sales report"
3. Click "New Conversation" button
4. Ask different question: "What is inventory status?"
5. Switch between conversations
6. Verify each maintains context
7. Check conversation titles auto-generated
8. View conversation history

### Expected Results
- âœ… Multiple conversations can be created
- âœ… Conversation list shows all conversations
- âœ… Each conversation maintains separate history
- âœ… Titles generated from first message
- âœ… Click conversation loads messages
- âœ… Messages display correctly

## ðŸ§ª Test Scenario 10: Anomaly Detection

### Objective
Test AI anomaly detection and alerts

### Steps
1. Create normal orders for several days
2. Create an outlier order (very large quantity)
3. Wait for BI to process
4. Navigate to BI Dashboard
5. Check alerts section
6. Verify anomaly detected
7. Review alert severity
8. Check insight details

### Expected Results
- âœ… Anomaly detected by AI
- âœ… Alert appears in alerts section
- âœ… Severity badge shown (Critical/Warning)
- âœ… Alert message describes issue
- âœ… Timestamp displayed
- âœ… Actionable recommendations provided

## ðŸ§ª Test Scenario 11: Demand Forecasting

### Objective
Test ML-based demand forecasting

### Steps
1. API test: `POST /api/ai-intelligence/forecast`
2. Send product ID and forecast period
3. Verify forecast response
4. Check confidence intervals
5. View trend analysis
6. Verify seasonal adjustments

### Expected Results
- âœ… Forecast data returned
- âœ… Multiple algorithms used (Holt-Winters, regression)
- âœ… Confidence intervals provided
- âœ… Trend detected
- âœ… Seasonal patterns identified

## ðŸ§ª Test Scenario 12: Feedback Loop

### Objective
Test AI improvement through feedback

### Steps
1. Ask 10 different questions
2. Provide feedback on each (mix of positive/negative)
3. Note initial confidence scores
4. Check learning progress
5. Ask similar questions again
6. Verify confidence improved
7. Check feedback stored in database
8. Review stats page for feedback metrics

### Expected Results
- âœ… All feedback recorded
- âœ… Positive feedback increases confidence
- âœ… Negative feedback triggers relearning
- âœ… Average rating calculated correctly
- âœ… Stats show feedback count
- âœ… AI adjusts responses based on feedback

## ðŸ§ª Test Scenario 13: Document Processing

### Objective
Verify document content extraction

### Steps
1. Create a test PDF with specific content
2. Upload to AI Assistant
3. After processing, ask question about content
4. Verify AI references the document
5. Check source shows "document" type
6. Verify relevance score displayed
7. Test with different formats (DOCX, TXT, CSV)

### Expected Results
- âœ… All formats processed successfully
- âœ… Content extracted accurately
- âœ… AI answers questions from documents
- âœ… Source attribution correct
- âœ… Relevance scores calculated
- âœ… Multiple documents can be referenced

## ðŸ§ª Test Scenario 14: Real-Time Updates

### Objective
Test WebSocket real-time updates

### Steps
1. Open two browser windows
2. Log in as same user in both
3. In window 1, create an order
4. Verify window 2 updates automatically
5. Test with AI conversations
6. Test with BI dashboard metrics

### Expected Results
- âœ… WebSocket connection established
- âœ… Real-time updates across windows
- âœ… No page refresh needed
- âœ… Data synchronizes instantly

## ðŸ§ª Test Scenario 15: Error Handling

### Objective
Test error handling and user feedback

### Steps
1. Upload file > 10MB (should fail)
2. Upload unsupported file type
3. Ask extremely long question
4. Try to edit another company's data
5. Submit form with missing required fields
6. Test with network disconnected

### Expected Results
- âœ… Clear error messages displayed
- âœ… File size limit enforced
- âœ… File type validation works
- âœ… Authorization errors caught
- âœ… Validation messages helpful
- âœ… Graceful degradation on network issues

## ðŸ“Š Performance Testing

### Metrics to Monitor
- Page load time: < 2 seconds
- AI response time: < 5 seconds
- Document upload: < 10 seconds
- API response time: < 500ms
- WebSocket latency: < 100ms

## ðŸ” Database Verification Queries

After testing, run these to verify data:

```sql
-- Check AI conversations created
SELECT COUNT(*) FROM ai_conversations;

-- Check learning data stored
SELECT COUNT(*) FROM ai_learning_data;

-- Check knowledge base entries
SELECT COUNT(*) FROM ai_knowledge_base;

-- Check feedback submitted
SELECT COUNT(*) FROM ai_feedback;

-- Check company relationships
SELECT * FROM company_supplier_relationships;

-- Verify data isolation
SELECT company_id, COUNT(*) as order_count 
FROM orders 
GROUP BY company_id;
```

## âœ… Success Criteria

All tests should pass with:
- âœ… No console errors
- âœ… No TypeScript compilation errors
- âœ… No database errors
- âœ… All UI elements render correctly
- âœ… All API calls succeed
- âœ… Data persists correctly
- âœ… Real-time updates work
- âœ… Security/isolation enforced
- âœ… Performance meets targets

## ðŸš¨ Known Issues to Watch

1. First AI query might be slow (cold start)
2. Large documents may take time to process
3. Ensure company_id exists on all users
4. Migration must be run before testing

## ðŸ“ Test Report Template

```
Test Run Date: [DATE]
Tester: [NAME]
Environment: Local Development

| Scenario | Status | Notes |
|----------|--------|-------|
| AI Assistant First Use | âœ…/âŒ | |
| Knowledge Upload | âœ…/âŒ | |
| Progressive Learning | âœ…/âŒ | |
| Company Management | âœ…/âŒ | |
| Supplier Relationships | âœ…/âŒ | |
| Data Isolation | âœ…/âŒ | |
| BI Dashboard | âœ…/âŒ | |
| Multi-Conversations | âœ…/âŒ | |
| Anomaly Detection | âœ…/âŒ | |
| Demand Forecasting | âœ…/âŒ | |
| Feedback Loop | âœ…/âŒ | |
| Document Processing | âœ…/âŒ | |
| Real-Time Updates | âœ…/âŒ | |
| Error Handling | âœ…/âŒ | |

Issues Found: [LIST]
Recommendations: [LIST]
```
