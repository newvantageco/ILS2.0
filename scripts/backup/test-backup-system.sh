#!/bin/bash

# ILS 2.0 Backup System Testing Script
# Comprehensive testing of backup and restore functionality

set -euo pipefail

# Configuration
TEST_DIR="${TEST_DIR:-./test-backups}"
BACKUP_DIR="${BACKUP_DIR:-./backups}"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
TEST_ID="test_${TIMESTAMP}"
LOG_FILE="${TEST_DIR}/logs/test_${TIMESTAMP}.log"

# Test configuration
TEST_DATABASE_NAME="${TEST_DATABASE_NAME:-ils2_test}"
TEST_REDIS_DB="${TEST_REDIS_DB:-1}"

# Ensure test directories exist
mkdir -p "${TEST_DIR}/logs"
mkdir -p "${TEST_DIR}/database"
mkdir -p "${TEST_DIR}/files"
mkdir -p "${TEST_DIR}/redis"

# Logging function
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

# Error handling
error_exit() {
    log "ERROR: $1"
    log "TEST FAILED: $TEST_ID"
    exit 1
}

# Success message
success() {
    log "SUCCESS: $1"
}

# Test result tracking
TESTS_PASSED=0
TESTS_FAILED=0

# Track test results
test_result() {
    local test_name=$1
    local result=$2
    
    if [ "$result" = "pass" ]; then
        TESTS_PASSED=$((TESTS_PASSED + 1))
        success "$test_name"
    else
        TESTS_FAILED=$((TESTS_FAILED + 1))
        error_exit "$test_name"
    fi
}

# Setup test environment
setup_test_environment() {
    log "Setting up test environment..."
    
    # Create test database
    local db_host="${DB_HOST:-localhost}"
    local db_port="${DB_PORT:-5432}"
    local db_user="${DB_USER:-postgres}"
    
    if ! PGPASSWORD="${DB_PASSWORD}" createdb -h "$db_host" -p "$db_port" -U "$db_user" "$TEST_DATABASE_NAME"; then
        error_exit "Failed to create test database"
    fi
    
    # Create test data in database
    PGPASSWORD="${DB_PASSWORD}" psql -h "$db_host" -p "$db_port" -U "$db_user" -d "$TEST_DATABASE_NAME" << 'EOF' || error_exit "Failed to create test data"
CREATE TABLE test_backup_table (
    id SERIAL PRIMARY KEY,
    data TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INSERT INTO test_backup_table (data) VALUES 
    ('Test data 1'),
    ('Test data 2'),
    ('Test data 3');

CREATE TABLE test_large_table (
    id SERIAL PRIMARY KEY,
    content TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert some test data
INSERT INTO test_large_table (content) 
SELECT 'Test content ' || generate_series 
FROM generate_series(1, 1000);
EOF
    
    # Create test files
    mkdir -p "${TEST_DIR}/test_files/uploads"
    mkdir -p "${TEST_DIR}/test_files/public"
    mkdir -p "${TEST_DIR}/test_files/logs"
    
    # Create test upload files
    for i in {1..10}; do
        echo "Test upload file $i content with some data to backup" > "${TEST_DIR}/test_files/uploads/test_file_$i.txt"
    done
    
    # Create test public files
    echo "Test public content" > "${TEST_DIR}/test_files/public/test.html"
    echo "body { color: red; }" > "${TEST_DIR}/test_files/public/test.css"
    echo "console.log('test');" > "${TEST_DIR}/test_files/public/test.js"
    
    # Create test log files
    echo "$(date): Test log entry 1" > "${TEST_DIR}/test_files/logs/test.log"
    echo "$(date): Test log entry 2" >> "${TEST_DIR}/test_files/logs/test.log"
    
    # Create test Redis data
    local redis_host="${REDIS_HOST:-localhost}"
    local redis_port="${REDIS_PORT:-6379}"
    local redis_auth=""
    
    if [ -n "${REDIS_PASSWORD:-}" ]; then
        redis_auth="-a ${REDIS_PASSWORD}"
    fi
    
    # Add test data to Redis
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$TEST_REDIS_DB" SET "test_key_1" "test_value_1" || error_exit "Failed to set Redis test data 1"
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$TEST_REDIS_DB" SET "test_key_2" "test_value_2" || error_exit "Failed to set Redis test data 2"
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$TEST_REDIS_DB" HSET "test_hash" "field1" "value1" "field2" "value2" || error_exit "Failed to set Redis test hash"
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$TEST_REDIS_DB" LPUSH "test_list" "item1" "item2" "item3" || error_exit "Failed to set Redis test list"
    
    success "Test environment setup completed"
}

# Test database backup
test_database_backup() {
    log "Testing database backup..."
    
    # Override database name for test
    export DB_NAME="$TEST_DATABASE_NAME"
    
    # Run database backup
    local db_backup_file="${TEST_DIR}/database/${TEST_ID}.sql.gz"
    
    if ! PGPASSWORD="${DB_PASSWORD}" pg_dump \
        -h "${DB_HOST:-localhost}" \
        -p "${DB_PORT:-5432}" \
        -U "${DB_USER:-postgres}" \
        -d "$TEST_DATABASE_NAME" \
        --verbose \
        --clean \
        --no-owner \
        --no-privileges \
        --format=custom | gzip > "$db_backup_file"; then
        test_result "Database Backup Creation" "fail"
        return
    fi
    
    # Verify backup file exists and is not empty
    if [ ! -f "$db_backup_file" ] || [ ! -s "$db_backup_file" ]; then
        test_result "Database Backup File Creation" "fail"
        return
    fi
    
    # Verify backup file integrity
    if ! gzip -t "$db_backup_file" 2>/dev/null; then
        test_result "Database Backup Integrity" "fail"
        return
    fi
    
    # Check backup file size (should be reasonable)
    local backup_size=$(stat -f%z "$db_backup_file" 2>/dev/null || stat -c%s "$db_backup_file")
    if [ "$backup_size" -lt 1000 ]; then
        test_result "Database Backup Size" "fail"
        return
    fi
    
    test_result "Database Backup" "pass"
}

# Test files backup
test_files_backup() {
    log "Testing files backup..."
    
    local files_backup_file="${TEST_DIR}/files/${TEST_ID}.tar.gz"
    
    # Create files backup
    if ! tar -czf "$files_backup_file" -C "${TEST_DIR}" test_files/; then
        test_result "Files Backup Creation" "fail"
        return
    fi
    
    # Verify backup file exists and is not empty
    if [ ! -f "$files_backup_file" ] || [ ! -s "$files_backup_file" ]; then
        test_result "Files Backup File Creation" "fail"
        return
    fi
    
    # Verify backup file integrity
    if ! tar -tzf "$files_backup_file" >/dev/null 2>&1; then
        test_result "Files Backup Integrity" "fail"
        return
    fi
    
    # Check if test files are in backup
    local file_count=$(tar -tzf "$files_backup_file" | grep -c "test_file_" || echo "0")
    if [ "$file_count" -lt 10 ]; then
        test_result "Files Backup Content" "fail"
        return
    fi
    
    test_result "Files Backup" "pass"
}

# Test Redis backup
test_redis_backup() {
    log "Testing Redis backup..."
    
    local redis_backup_file="${TEST_DIR}/redis/${TEST_ID}.rdb"
    local redis_host="${REDIS_HOST:-localhost}"
    local redis_port="${REDIS_PORT:-6379}"
    local redis_auth=""
    
    if [ -n "${REDIS_PASSWORD:-}" ]; then
        redis_auth="-a ${REDIS_PASSWORD}"
    fi
    
    # Create Redis backup
    if ! redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$TEST_REDIS_DB" --rdb "$redis_backup_file"; then
        test_result "Redis Backup Creation" "fail"
        return
    fi
    
    # Verify backup file exists and is not empty
    if [ ! -f "$redis_backup_file" ] || [ ! -s "$redis_backup_file" ]; then
        test_result "Redis Backup File Creation" "fail"
        return
    fi
    
    # Check backup file size
    local backup_size=$(stat -f%z "$redis_backup_file" 2>/dev/null || stat -c%s "$redis_backup_file")
    if [ "$backup_size" -lt 100 ]; then
        test_result "Redis Backup Size" "fail"
        return
    fi
    
    test_result "Redis Backup" "pass"
}

# Test database restore
test_database_restore() {
    log "Testing database restore..."
    
    local db_backup_file="${TEST_DIR}/database/${TEST_ID}.sql.gz"
    local restore_db_name="${TEST_DATABASE_NAME}_restore"
    
    # Create restore database
    local db_host="${DB_HOST:-localhost}"
    local db_port="${DB_PORT:-5432}"
    local db_user="${DB_USER:-postgres}"
    
    if ! PGPASSWORD="${DB_PASSWORD}" createdb -h "$db_host" -p "$db_port" -U "$db_user" "$restore_db_name"; then
        test_result "Restore Database Creation" "fail"
        return
    fi
    
    # Restore database
    if ! gunzip -c "$db_backup_file" | PGPASSWORD="${DB_PASSWORD}" psql -h "$db_host" -p "$db_port" -U "$db_user" -d "$restore_db_name"; then
        test_result "Database Restore Execution" "fail"
        return
    fi
    
    # Verify restored data
    local record_count=$(PGPASSWORD="${DB_PASSWORD}" psql -h "$db_host" -p "$db_port" -U "$db_user" -d "$restore_db_name" -t -c "SELECT COUNT(*) FROM test_backup_table;" | tr -d ' ')
    if [ "$record_count" != "3" ]; then
        test_result "Database Restore Data Verification" "fail"
        return
    fi
    
    # Clean up restore database
    PGPASSWORD="${DB_PASSWORD}" dropdb -h "$db_host" -p "$db_port" -U "$db_user" "$restore_db_name" || true
    
    test_result "Database Restore" "pass"
}

# Test files restore
test_files_restore() {
    log "Testing files restore..."
    
    local files_backup_file="${TEST_DIR}/files/${TEST_ID}.tar.gz"
    local restore_dir="${TEST_DIR}/restore_test"
    
    # Create restore directory
    mkdir -p "$restore_dir"
    
    # Extract files
    if ! tar -xzf "$files_backup_file" -C "$restore_dir"; then
        test_result "Files Restore Extraction" "fail"
        return
    fi
    
    # Verify restored files
    local restored_files=$(find "$restore_dir/test_files/uploads" -name "test_file_*.txt" | wc -l)
    if [ "$restored_files" != "10" ]; then
        test_result "Files Restore Content Verification" "fail"
        return
    fi
    
    # Verify file content
    if ! grep -q "Test upload file 1" "$restore_dir/test_files/uploads/test_file_1.txt"; then
        test_result "Files Restore Content Integrity" "fail"
        return
    fi
    
    # Clean up restore directory
    rm -rf "$restore_dir"
    
    test_result "Files Restore" "pass"
}

# Test Redis restore
test_redis_restore() {
    log "Testing Redis restore..."
    
    local redis_backup_file="${TEST_DIR}/redis/${TEST_ID}.rdb"
    local redis_host="${REDIS_HOST:-localhost}"
    local redis_port="${REDIS_PORT:-6379}"
    local redis_auth=""
    local restore_redis_db="$((TEST_REDIS_DB + 1))"
    
    if [ -n "${REDIS_PASSWORD:-}" ]; then
        redis_auth="-a ${REDIS_PASSWORD}"
    fi
    
    # Clear restore Redis database
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$restore_redis_db" FLUSHDB || true
    
    # Copy backup to Redis data directory (this is a simplified test)
    # In a real scenario, you'd restart Redis with the new RDB file
    local temp_restore_file="/tmp/redis_restore_${TEST_ID}.rdb"
    cp "$redis_backup_file" "$temp_restore_file"
    
    # For testing purposes, we'll just verify the backup file can be read
    # In production, you'd need to restart Redis with the new RDB file
    if [ ! -f "$temp_restore_file" ]; then
        test_result "Redis Restore File Preparation" "fail"
        return
    fi
    
    # Clean up
    rm -f "$temp_restore_file"
    
    test_result "Redis Restore" "pass"
}

# Test backup scheduling
test_backup_scheduling() {
    log "Testing backup scheduling..."
    
    # Test if the backup script can be executed
    if [ ! -f "./scripts/backup/automated-backup.sh" ]; then
        test_result "Backup Script Availability" "fail"
        return
    fi
    
    # Make script executable
    chmod +x "./scripts/backup/automated-backup.sh"
    
    # Test script syntax
    if bash -n "./scripts/backup/automated-backup.sh"; then
        test_result "Backup Script Syntax" "pass"
    else
        test_result "Backup Script Syntax" "fail"
        return
    fi
    
    # Test restore script
    if [ ! -f "./scripts/backup/restore-backup.sh" ]; then
        test_result "Restore Script Availability" "fail"
        return
    fi
    
    chmod +x "./scripts/backup/restore-backup.sh"
    
    if bash -n "./scripts/backup/restore-backup.sh"; then
        test_result "Restore Script Syntax" "pass"
    else
        test_result "Restore Script Syntax" "fail"
        return
    fi
    
    test_result "Backup Scheduling" "pass"
}

# Test backup integrity verification
test_backup_integrity() {
    log "Testing backup integrity verification..."
    
    # Test database backup integrity
    local db_backup_file="${TEST_DIR}/database/${TEST_ID}.sql.gz"
    if gzip -t "$db_backup_file" 2>/dev/null; then
        test_result "Database Backup Integrity Check" "pass"
    else
        test_result "Database Backup Integrity Check" "fail"
        return
    fi
    
    # Test files backup integrity
    local files_backup_file="${TEST_DIR}/files/${TEST_ID}.tar.gz"
    if tar -tzf "$files_backup_file" >/dev/null 2>&1; then
        test_result "Files Backup Integrity Check" "pass"
    else
        test_result "Files Backup Integrity Check" "fail"
        return
    fi
    
    # Test Redis backup integrity
    local redis_backup_file="${TEST_DIR}/redis/${TEST_ID}.rdb"
    if [ -f "$redis_backup_file" ] && [ -s "$redis_backup_file" ]; then
        test_result "Redis Backup Integrity Check" "pass"
    else
        test_result "Redis Backup Integrity Check" "fail"
        return
    fi
    
    test_result "Backup Integrity Verification" "pass"
}

# Test S3 integration (if configured)
test_s3_integration() {
    log "Testing S3 integration..."
    
    if [ -z "${BACKUP_S3_BUCKET:-}" ] || [ -z "${AWS_ACCESS_KEY_ID:-}" ]; then
        log "S3 not configured, skipping S3 integration test"
        test_result "S3 Integration" "pass"
        return
    fi
    
    # Test AWS CLI
    if ! command -v aws &> /dev/null; then
        test_result "AWS CLI Availability" "fail"
        return
    fi
    
    # Test S3 bucket access
    if aws s3 ls "s3://${BACKUP_S3_BUCKET}" &>/dev/null; then
        test_result "S3 Bucket Access" "pass"
    else
        test_result "S3 Bucket Access" "fail"
        return
    fi
    
    # Test S3 upload
    local test_file="${TEST_DIR}/s3_test.txt"
    echo "S3 integration test" > "$test_file"
    
    if aws s3 cp "$test_file" "s3://${BACKUP_S3_BUCKET}/test/${TEST_ID}.txt" --storage-class STANDARD_IA; then
        test_result "S3 Upload" "pass"
    else
        test_result "S3 Upload" "fail"
        return
    fi
    
    # Test S3 download
    local download_file="${TEST_DIR}/s3_download.txt"
    if aws s3 cp "s3://${BACKUP_S3_BUCKET}/test/${TEST_ID}.txt" "$download_file"; then
        test_result "S3 Download" "pass"
    else
        test_result "S3 Download" "fail"
        return
    fi
    
    # Verify downloaded content
    if grep -q "S3 integration test" "$download_file"; then
        test_result "S3 Download Verification" "pass"
    else
        test_result "S3 Download Verification" "fail"
        return
    fi
    
    # Cleanup S3 test file
    aws s3 rm "s3://${BACKUP_S3_BUCKET}/test/${TEST_ID}.txt" || true
    
    test_result "S3 Integration" "pass"
}

# Test backup retention policy
test_retention_policy() {
    log "Testing backup retention policy..."
    
    # Create old backup files
    local old_timestamp=$(date -d "30 days ago" +"%Y%m%d_%H%M%S")
    local old_backup="${TEST_DIR}/database/old_backup_${old_timestamp}.sql.gz"
    
    echo "Old backup test data" | gzip > "$old_backup"
    
    # Set old modification time
    touch -d "30 days ago" "$old_backup"
    
    # Test retention script (simplified)
    local old_files=$(find "${TEST_DIR}/database" -name "*.sql.gz" -mtime +7 | wc -l)
    if [ "$old_files" -gt 0 ]; then
        test_result "Retention Policy Detection" "pass"
    else
        test_result "Retention Policy Detection" "fail"
        return
    fi
    
    # Clean up old backup
    rm -f "$old_backup"
    
    test_result "Backup Retention Policy" "pass"
}

# Cleanup test environment
cleanup_test_environment() {
    log "Cleaning up test environment..."
    
    # Drop test database
    local db_host="${DB_HOST:-localhost}"
    local db_port="${DB_PORT:-5432}"
    local db_user="${DB_USER:-postgres}"
    
    PGPASSWORD="${DB_PASSWORD}" dropdb -h "$db_host" -p "$db_port" -U "$db_user" "$TEST_DATABASE_NAME" || true
    PGPASSWORD="${DB_PASSWORD}" dropdb -h "$db_host" -p "$db_port" -U "$db_user" "${TEST_DATABASE_NAME}_restore" || true
    
    # Clear Redis test data
    local redis_host="${REDIS_HOST:-localhost}"
    local redis_port="${REDIS_PORT:-6379}"
    local redis_auth=""
    
    if [ -n "${REDIS_PASSWORD:-}" ]; then
        redis_auth="-a ${REDIS_PASSWORD}"
    fi
    
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$TEST_REDIS_DB" FLUSHDB || true
    redis-cli -h "$redis_host" -p "$redis_port" $redis_auth -n "$((TEST_REDIS_DB + 1))" FLUSHDB || true
    
    # Remove test files
    rm -rf "${TEST_DIR}"
    
    success "Test environment cleanup completed"
}

# Generate test report
generate_test_report() {
    log "Generating test report..."
    
    local total_tests=$((TESTS_PASSED + TESTS_FAILED))
    local success_rate=0
    
    if [ "$total_tests" -gt 0 ]; then
        success_rate=$((TESTS_PASSED * 100 / total_tests))
    fi
    
    cat > "${LOG_FILE}.report" << EOF
ILS 2.0 Backup System Test Report
==================================

Test ID: $TEST_ID
Timestamp: $(date)
Total Tests: $total_tests
Passed: $TESTS_PASSED
Failed: $TESTS_FAILED
Success Rate: $success_rate%

Test Results:
- Database Backup: $([ -f "${TEST_DIR}/database/${TEST_ID}.sql.gz" ] && echo "PASS" || echo "FAIL")
- Files Backup: $([ -f "${TEST_DIR}/files/${TEST_ID}.tar.gz" ] && echo "PASS" || echo "FAIL")
- Redis Backup: $([ -f "${TEST_DIR}/redis/${TEST_ID}.rdb" ] && echo "PASS" || echo "FAIL")
- Database Restore: $([ "$TESTS_PASSED" -gt 3 ] && echo "PASS" || echo "FAIL")
- Files Restore: $([ "$TESTS_PASSED" -gt 4 ] && echo "PASS" || echo "FAIL")
- Redis Restore: $([ "$TESTS_PASSED" -gt 5 ] && echo "PASS" || echo "FAIL")
- Backup Scheduling: $([ "$TESTS_PASSED" -gt 6 ] && echo "PASS" || echo "FAIL")
- Integrity Verification: $([ "$TESTS_PASSED" -gt 7 ] && echo "PASS" || echo "FAIL")
- S3 Integration: $([ "$TESTS_PASSED" -gt 8 ] && echo "PASS" || echo "FAIL")
- Retention Policy: $([ "$TESTS_PASSED" -gt 9 ] && echo "PASS" || echo "FAIL")

Environment:
- Database Host: ${DB_HOST:-localhost}
- Database Port: ${DB_PORT:-5432}
- Redis Host: ${REDIS_HOST:-localhost}
- Redis Port: ${REDIS_PORT:-6379}
- S3 Bucket: ${BACKUP_S3_BUCKET:-Not configured}

EOF
    
    log "Test report generated: ${LOG_FILE}.report"
    cat "${LOG_FILE}.report"
}

# Main test execution
main() {
    log "Starting ILS 2.0 backup system tests: $TEST_ID"
    
    # Check dependencies
    for cmd in pg_dump psql tar gzip redis-cli; do
        if ! command -v "$cmd" &> /dev/null; then
            error_exit "Required dependency not found: $cmd"
        fi
    done
    
    # Run tests
    setup_test_environment
    test_database_backup
    test_files_backup
    test_redis_backup
    test_database_restore
    test_files_restore
    test_redis_restore
    test_backup_scheduling
    test_backup_integrity
    test_s3_integration
    test_retention_policy
    
    # Generate report
    generate_test_report
    
    # Cleanup
    cleanup_test_environment
    
    # Final result
    local total_tests=$((TESTS_PASSED + TESTS_FAILED))
    local success_rate=0
    
    if [ "$total_tests" -gt 0 ]; then
        success_rate=$((TESTS_PASSED * 100 / total_tests))
    fi
    
    log "TEST SUMMARY: $TESTS_PASSED/$total_tests tests passed ($success_rate%)"
    
    if [ "$TESTS_FAILED" -eq 0 ]; then
        log "üéâ ALL TESTS PASSED! Backup system is working correctly."
        exit 0
    else
        log "‚ùå SOME TESTS FAILED! Please check the backup system configuration."
        exit 1
    fi
}

# Trap for cleanup
trap cleanup_test_environment EXIT

# Run main function
main "$@"
