# ILS 2.0 - Production AI Service Dependencies
# Lightweight, Railway-optimized configuration
# Updated: November 2025

# ================================
# Core Web Framework
# ================================
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
python-multipart>=0.0.12
pydantic>=2.9.0
pydantic-settings>=2.5.0

# ================================
# AI/ML - External APIs (No Heavy Models)
# ================================
openai>=1.50.0
anthropic>=0.39.0

# ================================
# Embeddings - External API Only (Railway Optimized)
# ================================
# sentence-transformers REMOVED - uses ~1.5GB with torch dependencies
# We use OpenAI's embedding API instead: llm_service.generate_embeddings()
# This keeps the service lightweight (~200MB) and Railway-compatible

# ================================
# Database & Vector Store
# ================================
sqlalchemy>=2.0.35
psycopg2-binary>=2.9.9
pgvector>=0.3.5
asyncpg>=0.29.0

# ================================
# Security & Authentication
# ================================
python-jose[cryptography]>=3.3.0
PyJWT>=2.8.0
passlib[bcrypt]>=1.7.4
cryptography>=43.0.0

# ================================
# HTTP & Utilities
# ================================
httpx>=0.27.0
aiohttp>=3.10.0
requests>=2.32.0
python-dotenv>=1.0.1

# ================================
# Data Processing
# ================================
pandas>=2.2.0
numpy>=1.26.0,<2.0.0
# Using NumPy 1.x for better compatibility

# ================================
# Monitoring & Logging
# ================================
loguru>=0.7.2
prometheus-client>=0.21.0

# ================================
# Testing (Development Only - Excluded from Production)
# ================================
# pytest>=8.3.0
# pytest-asyncio>=0.24.0
# NOTE: httpx is required for production (used by llm_service.py)
httpx>=0.27.0
